{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/img/icon_wechat.png","path":"img/icon_wechat.png","modified":0,"renderable":0},{"_id":"source/img/404-bg.jpg","path":"img/404-bg.jpg","modified":0,"renderable":0},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.eot","path":"fonts/glyphicons-halflings-regular.eot","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff","path":"fonts/glyphicons-halflings-regular.woff","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.ttf","path":"fonts/glyphicons-halflings-regular.ttf","modified":0,"renderable":1},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff2","path":"fonts/glyphicons-halflings-regular.woff2","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/archive.styl","path":"css/archive.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/beantech.css","path":"css/beantech.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/beantech.min.css","path":"css/beantech.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/highlight.styl","path":"css/highlight.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/hux-blog.min.css","path":"css/hux-blog.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/rocket.styl","path":"css/rocket.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/signature.styl","path":"css/signature.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/widget.styl","path":"css/widget.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/toc.styl","path":"css/toc.styl","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/bootstrap.min.js","path":"js/bootstrap.min.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/hux-blog.js","path":"js/hux-blog.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/hux-blog.min.js","path":"js/hux-blog.min.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/jquery.tagcloud.js","path":"js/jquery.tagcloud.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/toc.js","path":"js/toc.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/totop.js","path":"js/totop.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/jquery.nav.js","path":"js/jquery.nav.js","modified":0,"renderable":1},{"_id":"source/img/header_img/Iron-Man-3.jpg","path":"img/header_img/Iron-Man-3.jpg","modified":0,"renderable":0},{"_id":"source/img/ironman-draw.png","path":"img/ironman-draw.png","modified":0,"renderable":0},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.svg","path":"fonts/glyphicons-halflings-regular.svg","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/bootstrap.min.css","path":"css/bootstrap.min.css","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/bootstrap.js","path":"js/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/beantech/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"source/img/signature/BeanTechSign-white.png","path":"img/signature/BeanTechSign-white.png","modified":0,"renderable":0},{"_id":"source/img/contact-bg.jpg","path":"img/contact-bg.jpg","modified":0,"renderable":0},{"_id":"themes/beantech/source/css/images/rocket.png","path":"css/images/rocket.png","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/images/ironman.png","path":"css/images/ironman.png","modified":0,"renderable":1},{"_id":"themes/beantech/source/css/bootstrap.css","path":"css/bootstrap.css","modified":0,"renderable":1},{"_id":"source/img/header_img/tf-logo-dark.png","path":"img/header_img/tf-logo-dark.png","modified":0,"renderable":0},{"_id":"source/img/signature/BeanTechSign-black.png","path":"img/signature/BeanTechSign-black.png","modified":0,"renderable":0},{"_id":"themes/beantech/source/js/jquery.js","path":"js/jquery.js","modified":0,"renderable":1},{"_id":"source/img/beantech-desktop.png","path":"img/beantech-desktop.png","modified":0,"renderable":0},{"_id":"source/img/header_img/tag-bg.png","path":"img/header_img/tag-bg.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-o.png","path":"img/header_img/home-bg-o.png","modified":0,"renderable":0},{"_id":"source/img/header_img/home-bg-2-dark.png","path":"img/header_img/home-bg-2-dark.png","modified":0,"renderable":0},{"_id":"source/img/header_img/archive-bg.png","path":"img/header_img/archive-bg.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"8938aa7aa7cd00e5c8c9e00915af7a57a0e399e6","modified":1539338426996},{"_id":"source/404.md","hash":"83c2c6d587beaa967a976e5969d60fa97fcdbe55","modified":1539338426996},{"_id":"themes/beantech/LICENSE","hash":"2b209f06bebeb2a8c2b7e187e436f3e1e1fbc8a7","modified":1539338427047},{"_id":"themes/beantech/_config.yml","hash":"6afd65c055d9b1c70ae67323cc869f1b4aa60348","modified":1539338427047},{"_id":"source/_posts/upstream.md","hash":"81176f46a2d3bd65e8e884145cd1577121ae020f","modified":1540698730517},{"_id":"source/about/index.md","hash":"ebca34cfe8d13ec641d17fcfec0127a966338f8e","modified":1540698730518},{"_id":"source/archive/index.md","hash":"279ff19668395f5c6b26417da99d2c1f3ecd5886","modified":1539338426997},{"_id":"source/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1540698730518},{"_id":"source/tags/index.md","hash":"9d558ce28d0d44c3463517088689bbca44bbb364","modified":1539338427046},{"_id":"themes/beantech/languages_to_be_added/de.yml","hash":"424a9c1e6ab69334d7873f6574da02ca960aa572","modified":1539338427048},{"_id":"themes/beantech/languages_to_be_added/default.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1539338427048},{"_id":"themes/beantech/languages_to_be_added/en.yml","hash":"97326c9e6518d9f379778178b3b8f9a58434725d","modified":1539338427049},{"_id":"themes/beantech/languages_to_be_added/es.yml","hash":"cb4eeca0ed3768a77e0cd216300f2b2549628b1b","modified":1539338427049},{"_id":"themes/beantech/languages_to_be_added/no.yml","hash":"8ca475a3b4f8efe6603030f0013aae39668230e1","modified":1539338427049},{"_id":"themes/beantech/languages_to_be_added/pl.yml","hash":"de7eb5850ae65ba7638e907c805fea90617a988c","modified":1539338427050},{"_id":"themes/beantech/languages_to_be_added/ru.yml","hash":"42df7afeb7a35dc46d272b7f4fb880a9d9ebcaa5","modified":1539338427050},{"_id":"themes/beantech/languages_to_be_added/zh-CN.yml","hash":"7bfcb0b8e97d7e5edcfca8ab26d55d9da2573c1c","modified":1539338427051},{"_id":"themes/beantech/languages_to_be_added/zh-TW.yml","hash":"9acac6cc4f8002c3fa53ff69fb8cf66c915bd016","modified":1539338427051},{"_id":"themes/beantech/layout/404.ejs","hash":"a4d73541a53e56b7dd46249c6d27cb59f4d97422","modified":1539338427052},{"_id":"themes/beantech/layout/about.ejs","hash":"edcf8fa3bf7093c974d418ffef42ac89c19af128","modified":1539338427058},{"_id":"themes/beantech/layout/archive.ejs","hash":"72a150c8dff0031a9107d12eaa7c2e6c6ce950d2","modified":1539338427058},{"_id":"themes/beantech/layout/index.ejs","hash":"dc8a6eaa00d1e7c33a40979afe0953ed5d7b512e","modified":1539338427059},{"_id":"themes/beantech/layout/layout.ejs","hash":"a5af5b99ac3456ab5da1a319455904b979b91601","modified":1539338427060},{"_id":"themes/beantech/layout/keynote.ejs","hash":"f5689862281e34dbe8402b0e72f632902e53e88b","modified":1539338427059},{"_id":"themes/beantech/layout/page.ejs","hash":"c90797e4394c5cb63c2515109480e766d04e486e","modified":1539338427060},{"_id":"themes/beantech/layout/tags.ejs","hash":"2c72eb2e89130658aa068d80d27b561b509c5dcd","modified":1539338427061},{"_id":"themes/beantech/layout/post.ejs","hash":"2d55684fc539dc281f9e2ec0409f09ea6ca43949","modified":1539338427061},{"_id":"source/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1539338426999},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1539338427068},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1539338427071},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1539338427070},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1539338427071},{"_id":"themes/beantech/source/css/archive.styl","hash":"715bcbd085eb95ec26c9805c11c374919cde971c","modified":1539338427062},{"_id":"themes/beantech/source/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1539338427062},{"_id":"themes/beantech/source/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1539338427063},{"_id":"themes/beantech/source/css/highlight.styl","hash":"e842080e6d580f0f70a7df71fbde3c4e49463c19","modified":1539338427065},{"_id":"themes/beantech/source/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1539338427066},{"_id":"themes/beantech/source/css/rocket.styl","hash":"e15c51c8566ecd943112e57592888dd318b6fa6a","modified":1539338427067},{"_id":"themes/beantech/source/css/signature.styl","hash":"88159b31c59d59c01a0b534af57242662a2a3969","modified":1539338427067},{"_id":"themes/beantech/source/css/widget.styl","hash":"7a9f735f5ef323dc2950fbd9d76daa16c9a0f1a9","modified":1539338427068},{"_id":"themes/beantech/source/css/toc.styl","hash":"6c9a2d5f6f981624e0c4b64323493e8614efea29","modified":1539338427068},{"_id":"themes/beantech/source/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1539338427072},{"_id":"themes/beantech/source/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1539338427073},{"_id":"themes/beantech/source/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1539338427073},{"_id":"themes/beantech/source/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1539338427077},{"_id":"themes/beantech/source/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1539338427077},{"_id":"themes/beantech/source/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1539338427077},{"_id":"themes/beantech/source/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1539338427076},{"_id":"themes/beantech/layout/_partial/head.ejs","hash":"3542d15bdf73aa59f05f566b7ecd2255e83ee370","modified":1539338427053},{"_id":"themes/beantech/layout/_partial/nav.ejs","hash":"4c905166c960852e9b9a3c9d5c680091e37b481f","modified":1539338427054},{"_id":"themes/beantech/layout/_partial/footer.ejs","hash":"c31863b1fa66fd915bc4913440be6c610d12af80","modified":1539338427052},{"_id":"themes/beantech/layout/_partial/header.ejs","hash":"aafb744601042f0270d2e6595129ac8a73ad2608","modified":1539338427053},{"_id":"themes/beantech/layout/_partial/pagination.ejs","hash":"557d6bb069a1d48af49ae912994653f44b32a570","modified":1539338427054},{"_id":"themes/beantech/layout/_partial/sidebar.ejs","hash":"2e4e528a555917b2a267da4db2440bcc4a7a65ab","modified":1539338427054},{"_id":"themes/beantech/layout/_partial/toc.ejs","hash":"837f01e8a20e5023b4b292d1b3141a399567da65","modified":1539338427055},{"_id":"themes/beantech/layout/_widget/archive.ejs","hash":"7594929d472806ca4c64d9906d9903a96de111a0","modified":1539338427055},{"_id":"themes/beantech/layout/_widget/category.ejs","hash":"1cf485def07dc06e870dc9613767c6c614bcf428","modified":1539338427056},{"_id":"themes/beantech/layout/_widget/friends-blog.ejs","hash":"734d3775017aedac185028924baf890a71a74548","modified":1539338427057},{"_id":"themes/beantech/layout/_widget/short-about.ejs","hash":"3b10bd768f6ef30a42b1703fbc9a88627f9bfdf1","modified":1539338427058},{"_id":"themes/beantech/layout/_widget/featured-tags.ejs","hash":"0c9ce1942f1943dc8891a9302a922ef1ffe300c5","modified":1539338427056},{"_id":"themes/beantech/layout/_widget/recent-posts.ejs","hash":"e08ab8ba60e31638006acf27f066b989a0a3c433","modified":1539338427057},{"_id":"source/img/header_img/Iron-Man-3.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1539338427008},{"_id":"source/img/ironman-draw.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1540698730521},{"_id":"themes/beantech/source/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1539338427070},{"_id":"themes/beantech/source/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1539338427065},{"_id":"themes/beantech/source/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1539338427072},{"_id":"themes/beantech/source/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1539338427076},{"_id":"source/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1540698730524},{"_id":"source/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1539338427007},{"_id":"themes/beantech/source/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1539338427066},{"_id":"themes/beantech/source/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1539338427066},{"_id":"themes/beantech/source/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1539338427064},{"_id":"source/img/header_img/tf-logo-dark.png","hash":"5c7bf8ade9de134f8c77a3c59e575abe9fc6cdd4","modified":1539338427039},{"_id":"source/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1540698730522},{"_id":"themes/beantech/source/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1539338427075},{"_id":"source/img/beantech-desktop.png","hash":"4a8f8b209c9db8fd5209f15b8e4590525e258b0f","modified":1539338427006},{"_id":"source/img/header_img/tag-bg.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1539338427037},{"_id":"source/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1539338427033},{"_id":"source/img/header_img/home-bg-2-dark.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1539338427026},{"_id":"source/img/header_img/archive-bg.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1539338427016},{"_id":"public/post-sitemap.xml","hash":"1890475e6873e6c21d41bb213c829a0f04a9cf95","modified":1540698936925},{"_id":"public/page-sitemap.xml","hash":"3b9e85e8359e955b3a15420b3c066f1ed8a59347","modified":1540698936962},{"_id":"public/sitemap.xsl","hash":"4321fa69dc1b8811d32b7a1478e5603e038cea1a","modified":1540698936980},{"_id":"public/sitemap.xml","hash":"51047b095191b58ed7c79ee585cd0534176dfdfc","modified":1540698936981},{"_id":"public/404.html","hash":"4905763872fe135a0c7f9ea8f1c0e375c878cac4","modified":1540698936988},{"_id":"public/tags/index.html","hash":"9936f00c8bc3d12bd946960e2fd49081527c780b","modified":1540698936988},{"_id":"public/archive/index.html","hash":"b4a64296a75062e34017893324334f6939ee8234","modified":1540698936988},{"_id":"public/archives/index.html","hash":"3185da887d3a0a84a89b7be765aa7360e3208e18","modified":1540698936988},{"_id":"public/archives/2018/index.html","hash":"e460ee70ad13d6daf4b72966a345e571ce86483c","modified":1540698936989},{"_id":"public/archives/2018/10/index.html","hash":"ece3b183842dd144bfa1ad4e81da34eee4cceacb","modified":1540698936989},{"_id":"public/index.html","hash":"74f6b18d55786064d26ac9a7adcee0bb7a11d6ba","modified":1540698936989},{"_id":"public/2018/10/13/upstream/index.html","hash":"4ff89b2721ad72bdaf47678454a4eb4b758c54a5","modified":1540698936989},{"_id":"public/about/index.html","hash":"ac0ebaa83504e72e2a4156997cd33d8dad74b497","modified":1540698936989},{"_id":"public/CNAME","hash":"8938aa7aa7cd00e5c8c9e00915af7a57a0e399e6","modified":1540698936994},{"_id":"public/img/icon_wechat.png","hash":"4188058026609de06c6cac88b349a2da831a1783","modified":1540698936994},{"_id":"public/fonts/glyphicons-halflings-regular.eot","hash":"86b6f62b7853e67d3e635f6512a5a5efc58ea3c3","modified":1540698936994},{"_id":"public/fonts/glyphicons-halflings-regular.woff","hash":"278e49a86e634da6f2a02f3b47dd9d2a8f26210f","modified":1540698936994},{"_id":"public/fonts/glyphicons-halflings-regular.ttf","hash":"44bc1850f570972267b169ae18f1cb06b611ffa2","modified":1540698936995},{"_id":"public/fonts/glyphicons-halflings-regular.woff2","hash":"ca35b697d99cae4d1b60f2d60fcd37771987eb07","modified":1540698936995},{"_id":"public/css/images/rocket.png","hash":"6dee0406955aa9b7a261161d30f2538a671e806b","modified":1540698936995},{"_id":"public/css/images/ironman.png","hash":"2f0db0ab15d466c4065d9f6102fdf829726d9e3f","modified":1540698936995},{"_id":"public/img/header_img/Iron-Man-3.jpg","hash":"62a9a76854503c327990cc8d10de293ab6e9588f","modified":1540698937217},{"_id":"public/fonts/glyphicons-halflings-regular.svg","hash":"de51a8494180a6db074af2dee2383f0a363c5b08","modified":1540698937219},{"_id":"public/css/archive.css","hash":"8db895ebaeff19ac145c961abcfd5d4a8d67a8ea","modified":1540698937225},{"_id":"public/css/highlight.css","hash":"03d1f0a648e9bdf7b1f57d217313cbac5d0c7eb1","modified":1540698937225},{"_id":"public/css/rocket.css","hash":"9456fd92f729e09d6de8cda70f95d78e0d789c70","modified":1540698937225},{"_id":"public/css/signature.css","hash":"820fa4743cea34a61808cd8f7de528605c32d7e3","modified":1540698937225},{"_id":"public/css/widget.css","hash":"da95ad3f1938f24d20f1fa77d7a38f0c392b5ec8","modified":1540698937225},{"_id":"public/css/toc.css","hash":"2062bf4e5b219654e0d4bf470f5eef1be213da95","modified":1540698937226},{"_id":"public/js/hux-blog.js","hash":"4b4d3c557405d04c3087d36c13e2834fe05c0f73","modified":1540698937226},{"_id":"public/js/hux-blog.min.js","hash":"1563e7f70550ac6b30803d6f449719b853200e35","modified":1540698937226},{"_id":"public/js/jquery.tagcloud.js","hash":"4e5fd0b07f3bd935f2e603710447e039e3677211","modified":1540698937226},{"_id":"public/js/toc.js","hash":"41e52551731854224c249d53010c1bae5aa92ffa","modified":1540698937226},{"_id":"public/js/totop.js","hash":"c05360f6fc699ac12e794b1764b4a952713a3017","modified":1540698937226},{"_id":"public/js/jquery.nav.js","hash":"ef2160a456176a4d09cc0b95d52b27dfbbadf2d8","modified":1540698937226},{"_id":"public/css/beantech.css","hash":"4c361354fd8e9851923fb21a620bc079380ebcd8","modified":1540698937226},{"_id":"public/css/beantech.min.css","hash":"05a06230b1a9eca0b30cece54a397008cb77dc50","modified":1540698937226},{"_id":"public/css/hux-blog.min.css","hash":"1baef04de262aeb7023d835429b49a805ac4ab40","modified":1540698937226},{"_id":"public/js/bootstrap.min.js","hash":"b3f2ef9f985e7906c9360756b73cd64bf7733647","modified":1540698937226},{"_id":"public/css/bootstrap.min.css","hash":"fec7b176a4b9a67c0eb5d184f57b84297efc23aa","modified":1540698937227},{"_id":"public/js/bootstrap.js","hash":"f8752e9ae24daec0a0baffd7819122f8c6fd9103","modified":1540698937227},{"_id":"public/js/jquery.min.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1540698937227},{"_id":"public/css/bootstrap.css","hash":"41c54bf695145ae0b4d9020a1da308ceb05dcaf3","modified":1540698937227},{"_id":"public/js/jquery.js","hash":"1852661bd11a09ca9b9cb63d1aa6ff390fffaf4e","modified":1540698937227},{"_id":"public/img/404-bg.jpg","hash":"68f7d525269a94287e0ad18713ae232fb59dcf71","modified":1540698937227},{"_id":"public/img/signature/BeanTechSign-white.png","hash":"34289ed41cf9ddac2d56be46fbb1515b7d5913cd","modified":1540698937227},{"_id":"public/img/ironman-draw.png","hash":"7d6a06b4b544ab146c3b3e8474edc33f14ac6e4d","modified":1540698937231},{"_id":"public/img/signature/BeanTechSign-black.png","hash":"94b7102e819fd6ee082d3fb0166f4de7458c22ff","modified":1540698937232},{"_id":"public/img/header_img/tf-logo-dark.png","hash":"5c7bf8ade9de134f8c77a3c59e575abe9fc6cdd4","modified":1540698937232},{"_id":"public/img/contact-bg.jpg","hash":"6af63305c923899017e727b5ca968a2703bc08cf","modified":1540698937235},{"_id":"public/img/header_img/tag-bg.png","hash":"e83cd7b04ff85bcbc9bd3ebf5e57a55166e82568","modified":1540698937280},{"_id":"public/img/beantech-desktop.png","hash":"4a8f8b209c9db8fd5209f15b8e4590525e258b0f","modified":1540698937283},{"_id":"public/img/header_img/home-bg-o.png","hash":"134ece4cb4c49c7ca1403a5afe7f46d0e2f9ecbb","modified":1540698937289},{"_id":"public/img/header_img/home-bg-2-dark.png","hash":"da6a3d5ca787bdc25e69655abd879b4f821aeb30","modified":1540698937292},{"_id":"public/img/header_img/archive-bg.png","hash":"6bf9c224543ec54e250309db89cbdf46e0c4b5ba","modified":1540698937298}],"Category":[],"Data":[],"Page":[{"layout":"404","description":"你来到了没有知识的荒原 :(","header-img":"img/404-bg.jpg","_content":"","source":"404.md","raw":"---\nlayout: 404\ndescription: \"你来到了没有知识的荒原 :(\"\nheader-img: \"img/404-bg.jpg\"\n---\n","date":"2018-10-12T10:00:26.996Z","updated":"2018-10-12T10:00:26.996Z","path":"404.html","title":"","comments":1,"_id":"cjnscd7sz00008zs6kwc8g498","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"about","title":"About","date":"2016-04-21T04:48:33.000Z","description":"Wish for the Best, Prepare for the Worst","header-img":"img/header_img/Iron-Man-3.jpg","comments":1,"_content":"\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","source":"about/index.md","raw":"---\nlayout: \"about\"\ntitle: \"About\"\ndate: 2016-04-21 04:48:33\ndescription: \"Wish for the Best, Prepare for the Worst\"\nheader-img: \"img/header_img/Iron-Man-3.jpg\"\ncomments: true\n---\n\n> 光有好奇心而不去實踐，等於自願放棄成功機會\n> 別為自己畫地自限，Just Do It！！\n","updated":"2018-10-28T03:52:10.518Z","path":"about/index.html","_id":"cjnscd7tq00028zs6xogmlj53","content":"<blockquote>\n<p>光有好奇心而不去實踐，等於自願放棄成功機會<br>\n別為自己畫地自限，Just Do It！！</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>光有好奇心而不去實踐，等於自願放棄成功機會<br>\n別為自己畫地自限，Just Do It！！</p>\n</blockquote>\n"},{"layout":"archive","title":"Archives","header-img":"img/header_img/archive-bg.png","comments":0,"date":"2017-03-20T20:49:56.000Z","description":"Hey, this is archives","_content":"","source":"archive/index.md","raw":"---\nlayout: \"archive\"\ntitle: \"Archives\"\nheader-img: \"img/header_img/archive-bg.png\"\ncomments: false\ndate: 2017-03-20 20:49:56\ndescription: \"Hey, this is archives\"\n---\n","updated":"2018-10-12T10:00:26.997Z","path":"archive/index.html","_id":"cjnscd7tr00038zs624lobvi7","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"tags","title":"Tags","description":"Hey, this is Tags.","header-img":"img/header_img/tag-bg.png","_content":"","source":"tags/index.md","raw":"---\nlayout: \"tags\"\ntitle: \"Tags\"\ndescription: \"Hey, this is Tags.\"\nheader-img: \"img/header_img/tag-bg.png\"\n---\n","date":"2018-10-12T10:00:27.046Z","updated":"2018-10-12T10:00:27.046Z","path":"tags/index.html","comments":1,"_id":"cjnscd7tt00048zs6rsx46i98","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"layout":"nginx","title":"upstream","date":"2018-10-12T17:10:21.000Z","_content":"\nNginx 的 HttpUpstreamModule 提供对后端(backend)服务器的简单负载均衡。\n\n1.新建3台vagrant虚拟机 A（192.168.33.10）、B（192.168.33.20）、C（192.168.33.30）\n2.本地配置host\n192.168.33.10  z.com\n3.A 配置upstream模块\n3.1 打开nginx.conf 在 http{}标签内配置upstream模块（以下是权重模式）\n\n```php\nupstream z.com {\n                server 192.168.33.20:80 weight=1;\n                server 192.168.33.30:80 weight=5;\n        }\n```\n\n3.2 配置server\n```php\n\nserver {\n        listen 80;\n        server_name a.com;\n        access_log  logs/a.access.log main;\n        location / {#通用规则\n           proxy_pass http://a.com;#配置代理\n        }\n}\n```\n\n3.3 分别在B、C虚拟机中配置server\n```php\n\nserver {\n        listen 80;\n        server_name a.com;\n        access_log  logs/a.access.log main;\n\n        location / {\n                root /home/work/test;\n                index index.html index.php;\n\n                }\n        }\n```\n        \n\n3.4 在B、C中的/home/work/test目录下新建index.html文件，并输出不同内容（为了确认当前访问的是哪台机器）\n3.5 重启3台虚拟机的nginx\n\n浏览器访问z.com可以看到A服务器会按照配置的权重比轮询B、C两台服务器\n为了测试宕机情况，手动将B服务器关机\nshutdown -h now\n继续访问z.com 会发现自动剔除了B服务器，每次访问都会命中C。\n\n\n                \n\n一、分配方式 \nNginx的upstream支持5种分配方式\n1、轮询 轮询是upstream的默认分配方式,即每个请求按照时间顺序轮流分配到不同的后端服务器,如果某个后端服务器down掉后,能自动剔除。\n```php\n\nupstream backend { \nserver 192.168.1.101:8888; \nserver 192.168.1.102:8888; \nserver 192.168.1.103:8888; \n}\n```\n \n\n2、weight 轮询的加强版,即可以指定轮询比率,weight和访问几率成正比,主要应用于后端服务器异质的场景下。\n\n```php\nupstream backend { \nserver 192.168.1.101 weight=1; \nserver 192.168.1.102 weight=2; \nserver 192.168.1.103 weight=3; \n} \n```\n\n3、ip_hash 每个请求按照访问ip(即Nginx的前置服务器或者客户端IP)的hash结果分配,这样每个访客会固定访问一个后端服务器,可以解决session一致问题。\n\n```php\nupstream backend { \nip_hash; \nserver 192.168.1.101:7777; \nserver 192.168.1.102:8888 weight=2; \nserver 192.168.1.103:9999 backup; \n} \n```\n\n注意:1、当负载调度算法为ip_hash时,后端服务器在负载均衡调度中的状态不能是weight和backup。2、导致负载不均衡。\n4、fair fair顾名思义,公平地按照后端服务器的响应时间(rt)来分配请求,响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法,必须下载Nginx的upstr_fair模块。\n\n```php\nupstream backend { \nserver 192.168.1.101; \nserver 192.168.1.102; \nserver 192.168.1.103; fair; \n} \n```\n\n5、url_hash,目前用consistent_hash替代url_hash与ip_hash类似,但是按照访问url的hash结果来分配请求,使得每个url定向到同一个后端服务器,主要应用于后端服务器为缓存时的场景下。\n```php\n\nupstream backend { \nserver 192.168.1.101; \nserver 192.168.1.102; \nserver 192.168.1.103; \nhash $request_uri; \nhash_method crc32; \n} \n```\n\n其中,hash_method为使用的hash算法,需要注意的是:此时,server语句中不能加weight等参数。\n提示:url_hash用途cache服务业务,memcached,squid,varnish。特点:每个rs都是不同的。\n\n\n\n参数说明:\nserver address parameters\nserver:关键字,必选。\naddress:主机名、域名、ip或unix socket,也可以指定端口号,必选。\nparameters:可选参数,可选参数如下:\n1.down:表示当前server已停用\n2.backup:表示当前server是备用服务器,只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。\n3.weight:表示当前server负载权重,权重越大被请求几率越大。默认是1.\n4.max_fails和fail_timeout一般会关联使用,如果某台server在fail_timeout时间内出现了max_fails次连接失败,那么Nginx会认为其已经挂掉了,从而在fail_timeout时间内不再去请求它,fail_timeout默认是10s,max_fails默认是1,即默认情况是只要发生错误就认为服务器挂掉了,如果将max_fails设置为0,则表示取消这项检查。\n```php\n\nupstream backend { \nserver backend1.example.com weight=5; \nserver 127.0.0.1:8080 max_fails=3 fail_timeout=30s; \nserver unix:/tmp/backend3; \n} \n\n```\n","source":"_posts/upstream.md","raw":"---\nlayout: nginx\ntitle: upstream\ndate: 2018-10-12 17:10:21\ntags:\n---\n\nNginx 的 HttpUpstreamModule 提供对后端(backend)服务器的简单负载均衡。\n\n1.新建3台vagrant虚拟机 A（192.168.33.10）、B（192.168.33.20）、C（192.168.33.30）\n2.本地配置host\n192.168.33.10  z.com\n3.A 配置upstream模块\n3.1 打开nginx.conf 在 http{}标签内配置upstream模块（以下是权重模式）\n\n```php\nupstream z.com {\n                server 192.168.33.20:80 weight=1;\n                server 192.168.33.30:80 weight=5;\n        }\n```\n\n3.2 配置server\n```php\n\nserver {\n        listen 80;\n        server_name a.com;\n        access_log  logs/a.access.log main;\n        location / {#通用规则\n           proxy_pass http://a.com;#配置代理\n        }\n}\n```\n\n3.3 分别在B、C虚拟机中配置server\n```php\n\nserver {\n        listen 80;\n        server_name a.com;\n        access_log  logs/a.access.log main;\n\n        location / {\n                root /home/work/test;\n                index index.html index.php;\n\n                }\n        }\n```\n        \n\n3.4 在B、C中的/home/work/test目录下新建index.html文件，并输出不同内容（为了确认当前访问的是哪台机器）\n3.5 重启3台虚拟机的nginx\n\n浏览器访问z.com可以看到A服务器会按照配置的权重比轮询B、C两台服务器\n为了测试宕机情况，手动将B服务器关机\nshutdown -h now\n继续访问z.com 会发现自动剔除了B服务器，每次访问都会命中C。\n\n\n                \n\n一、分配方式 \nNginx的upstream支持5种分配方式\n1、轮询 轮询是upstream的默认分配方式,即每个请求按照时间顺序轮流分配到不同的后端服务器,如果某个后端服务器down掉后,能自动剔除。\n```php\n\nupstream backend { \nserver 192.168.1.101:8888; \nserver 192.168.1.102:8888; \nserver 192.168.1.103:8888; \n}\n```\n \n\n2、weight 轮询的加强版,即可以指定轮询比率,weight和访问几率成正比,主要应用于后端服务器异质的场景下。\n\n```php\nupstream backend { \nserver 192.168.1.101 weight=1; \nserver 192.168.1.102 weight=2; \nserver 192.168.1.103 weight=3; \n} \n```\n\n3、ip_hash 每个请求按照访问ip(即Nginx的前置服务器或者客户端IP)的hash结果分配,这样每个访客会固定访问一个后端服务器,可以解决session一致问题。\n\n```php\nupstream backend { \nip_hash; \nserver 192.168.1.101:7777; \nserver 192.168.1.102:8888 weight=2; \nserver 192.168.1.103:9999 backup; \n} \n```\n\n注意:1、当负载调度算法为ip_hash时,后端服务器在负载均衡调度中的状态不能是weight和backup。2、导致负载不均衡。\n4、fair fair顾名思义,公平地按照后端服务器的响应时间(rt)来分配请求,响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法,必须下载Nginx的upstr_fair模块。\n\n```php\nupstream backend { \nserver 192.168.1.101; \nserver 192.168.1.102; \nserver 192.168.1.103; fair; \n} \n```\n\n5、url_hash,目前用consistent_hash替代url_hash与ip_hash类似,但是按照访问url的hash结果来分配请求,使得每个url定向到同一个后端服务器,主要应用于后端服务器为缓存时的场景下。\n```php\n\nupstream backend { \nserver 192.168.1.101; \nserver 192.168.1.102; \nserver 192.168.1.103; \nhash $request_uri; \nhash_method crc32; \n} \n```\n\n其中,hash_method为使用的hash算法,需要注意的是:此时,server语句中不能加weight等参数。\n提示:url_hash用途cache服务业务,memcached,squid,varnish。特点:每个rs都是不同的。\n\n\n\n参数说明:\nserver address parameters\nserver:关键字,必选。\naddress:主机名、域名、ip或unix socket,也可以指定端口号,必选。\nparameters:可选参数,可选参数如下:\n1.down:表示当前server已停用\n2.backup:表示当前server是备用服务器,只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。\n3.weight:表示当前server负载权重,权重越大被请求几率越大。默认是1.\n4.max_fails和fail_timeout一般会关联使用,如果某台server在fail_timeout时间内出现了max_fails次连接失败,那么Nginx会认为其已经挂掉了,从而在fail_timeout时间内不再去请求它,fail_timeout默认是10s,max_fails默认是1,即默认情况是只要发生错误就认为服务器挂掉了,如果将max_fails设置为0,则表示取消这项检查。\n```php\n\nupstream backend { \nserver backend1.example.com weight=5; \nserver 127.0.0.1:8080 max_fails=3 fail_timeout=30s; \nserver unix:/tmp/backend3; \n} \n\n```\n","slug":"upstream","published":1,"updated":"2018-10-28T03:52:10.517Z","comments":1,"photos":[],"link":"","_id":"cjnscd7tm00018zs67axlmxxt","content":"<p>Nginx 的 HttpUpstreamModule 提供对后端(backend)服务器的简单负载均衡。</p>\n<p>1.新建3台vagrant虚拟机 A（192.168.33.10）、B（192.168.33.20）、C（192.168.33.30）<br>\n2.本地配置host<br>\n192.168.33.10  <a href=\"http://z.com\" target=\"_blank\" rel=\"noopener\">z.com</a><br>\n3.A 配置upstream模块<br>\n3.1 打开nginx.conf 在 http{}标签内配置upstream模块（以下是权重模式）</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream z.com &#123;</span><br><span class=\"line\">                server <span class=\"number\">192.168</span><span class=\"number\">.33</span><span class=\"number\">.20</span>:<span class=\"number\">80</span> weight=<span class=\"number\">1</span>;</span><br><span class=\"line\">                server <span class=\"number\">192.168</span><span class=\"number\">.33</span><span class=\"number\">.30</span>:<span class=\"number\">80</span> weight=<span class=\"number\">5</span>;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>3.2 配置server</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen <span class=\"number\">80</span>;</span><br><span class=\"line\">        server_name a.com;</span><br><span class=\"line\">        access_log  logs/a.access.log main;</span><br><span class=\"line\">        location / &#123;<span class=\"comment\">#通用规则</span></span><br><span class=\"line\">           proxy_pass http:<span class=\"comment\">//a.com;#配置代理</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3.3 分别在B、C虚拟机中配置server</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen <span class=\"number\">80</span>;</span><br><span class=\"line\">        server_name a.com;</span><br><span class=\"line\">        access_log  logs/a.access.log main;</span><br><span class=\"line\"></span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">                root /home/work/test;</span><br><span class=\"line\">                index index.html index.php;</span><br><span class=\"line\"></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>3.4 在B、C中的/home/work/test目录下新建index.html文件，并输出不同内容（为了确认当前访问的是哪台机器）<br>\n3.5 重启3台虚拟机的nginx</p>\n<p>浏览器访问z.com可以看到A服务器会按照配置的权重比轮询B、C两台服务器<br>\n为了测试宕机情况，手动将B服务器关机<br>\nshutdown -h now<br>\n<a href=\"http://xn--z-d36csa242kpmm.com\" target=\"_blank\" rel=\"noopener\">继续访问z.com</a> 会发现自动剔除了B服务器，每次访问都会命中C。</p>\n<p>一、分配方式<br>\nNginx的upstream支持5种分配方式<br>\n1、轮询 轮询是upstream的默认分配方式,即每个请求按照时间顺序轮流分配到不同的后端服务器,如果某个后端服务器down掉后,能自动剔除。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>2、weight 轮询的加强版,即可以指定轮询比率,weight和访问几率成正比,主要应用于后端服务器异质的场景下。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span> weight=<span class=\"number\">1</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span> weight=<span class=\"number\">2</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span> weight=<span class=\"number\">3</span>; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3、ip_hash 每个请求按照访问ip(即Nginx的前置服务器或者客户端IP)的hash结果分配,这样每个访客会固定访问一个后端服务器,可以解决session一致问题。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">ip_hash; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>:<span class=\"number\">7777</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>:<span class=\"number\">8888</span> weight=<span class=\"number\">2</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>:<span class=\"number\">9999</span> backup; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>注意:1、当负载调度算法为ip_hash时,后端服务器在负载均衡调度中的状态不能是weight和backup。2、导致负载不均衡。<br>\n4、fair fair顾名思义,公平地按照后端服务器的响应时间(rt)来分配请求,响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法,必须下载Nginx的upstr_fair模块。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>; fair; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>5、url_hash,目前用consistent_hash替代url_hash与ip_hash类似,但是按照访问url的hash结果来分配请求,使得每个url定向到同一个后端服务器,主要应用于后端服务器为缓存时的场景下。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>; </span><br><span class=\"line\">hash $request_uri; </span><br><span class=\"line\">hash_method crc32; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中,hash_method为使用的hash算法,需要注意的是:此时,server语句中不能加weight等参数。<br>\n提示:url_hash用途cache服务业务,memcached,squid,varnish。特点:每个rs都是不同的。</p>\n<p>参数说明:<br>\nserver address parameters<br>\nserver:关键字,必选。<br>\naddress:主机名、域名、ip或unix socket,也可以指定端口号,必选。<br>\nparameters:可选参数,可选参数如下:<br>\n1.down:表示当前server已停用<br>\n2.backup:表示当前server是备用服务器,只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。<br>\n3.weight:表示当前server负载权重,权重越大被请求几率越大。默认是1.<br>\n4.max_fails和fail_timeout一般会关联使用,如果某台server在fail_timeout时间内出现了max_fails次连接失败,那么Nginx会认为其已经挂掉了,从而在fail_timeout时间内不再去请求它,fail_timeout默认是10s,max_fails默认是1,即默认情况是只要发生错误就认为服务器挂掉了,如果将max_fails设置为0,则表示取消这项检查。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server backend1.example.com weight=<span class=\"number\">5</span>; </span><br><span class=\"line\">server <span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span>:<span class=\"number\">8080</span> max_fails=<span class=\"number\">3</span> fail_timeout=<span class=\"number\">30</span>s; </span><br><span class=\"line\">server unix:/tmp/backend3; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<p>Nginx 的 HttpUpstreamModule 提供对后端(backend)服务器的简单负载均衡。</p>\n<p>1.新建3台vagrant虚拟机 A（192.168.33.10）、B（192.168.33.20）、C（192.168.33.30）<br>\n2.本地配置host<br>\n192.168.33.10  <a href=\"http://z.com\" target=\"_blank\" rel=\"noopener\">z.com</a><br>\n3.A 配置upstream模块<br>\n3.1 打开nginx.conf 在 http{}标签内配置upstream模块（以下是权重模式）</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream z.com &#123;</span><br><span class=\"line\">                server <span class=\"number\">192.168</span><span class=\"number\">.33</span><span class=\"number\">.20</span>:<span class=\"number\">80</span> weight=<span class=\"number\">1</span>;</span><br><span class=\"line\">                server <span class=\"number\">192.168</span><span class=\"number\">.33</span><span class=\"number\">.30</span>:<span class=\"number\">80</span> weight=<span class=\"number\">5</span>;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>3.2 配置server</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen <span class=\"number\">80</span>;</span><br><span class=\"line\">        server_name a.com;</span><br><span class=\"line\">        access_log  logs/a.access.log main;</span><br><span class=\"line\">        location / &#123;<span class=\"comment\">#通用规则</span></span><br><span class=\"line\">           proxy_pass http:<span class=\"comment\">//a.com;#配置代理</span></span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3.3 分别在B、C虚拟机中配置server</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">server &#123;</span><br><span class=\"line\">        listen <span class=\"number\">80</span>;</span><br><span class=\"line\">        server_name a.com;</span><br><span class=\"line\">        access_log  logs/a.access.log main;</span><br><span class=\"line\"></span><br><span class=\"line\">        location / &#123;</span><br><span class=\"line\">                root /home/work/test;</span><br><span class=\"line\">                index index.html index.php;</span><br><span class=\"line\"></span><br><span class=\"line\">                &#125;</span><br><span class=\"line\">        &#125;</span><br></pre></td></tr></table></figure>\n<p>3.4 在B、C中的/home/work/test目录下新建index.html文件，并输出不同内容（为了确认当前访问的是哪台机器）<br>\n3.5 重启3台虚拟机的nginx</p>\n<p>浏览器访问z.com可以看到A服务器会按照配置的权重比轮询B、C两台服务器<br>\n为了测试宕机情况，手动将B服务器关机<br>\nshutdown -h now<br>\n<a href=\"http://xn--z-d36csa242kpmm.com\" target=\"_blank\" rel=\"noopener\">继续访问z.com</a> 会发现自动剔除了B服务器，每次访问都会命中C。</p>\n<p>一、分配方式<br>\nNginx的upstream支持5种分配方式<br>\n1、轮询 轮询是upstream的默认分配方式,即每个请求按照时间顺序轮流分配到不同的后端服务器,如果某个后端服务器down掉后,能自动剔除。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>:<span class=\"number\">8888</span>; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>2、weight 轮询的加强版,即可以指定轮询比率,weight和访问几率成正比,主要应用于后端服务器异质的场景下。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span> weight=<span class=\"number\">1</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span> weight=<span class=\"number\">2</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span> weight=<span class=\"number\">3</span>; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>3、ip_hash 每个请求按照访问ip(即Nginx的前置服务器或者客户端IP)的hash结果分配,这样每个访客会固定访问一个后端服务器,可以解决session一致问题。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">ip_hash; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>:<span class=\"number\">7777</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>:<span class=\"number\">8888</span> weight=<span class=\"number\">2</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>:<span class=\"number\">9999</span> backup; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>注意:1、当负载调度算法为ip_hash时,后端服务器在负载均衡调度中的状态不能是weight和backup。2、导致负载不均衡。<br>\n4、fair fair顾名思义,公平地按照后端服务器的响应时间(rt)来分配请求,响应时间短即rt小的后端服务器优先分配请求。如果需要使用这种调度算法,必须下载Nginx的upstr_fair模块。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>; fair; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>5、url_hash,目前用consistent_hash替代url_hash与ip_hash类似,但是按照访问url的hash结果来分配请求,使得每个url定向到同一个后端服务器,主要应用于后端服务器为缓存时的场景下。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.101</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.102</span>; </span><br><span class=\"line\">server <span class=\"number\">192.168</span><span class=\"number\">.1</span><span class=\"number\">.103</span>; </span><br><span class=\"line\">hash $request_uri; </span><br><span class=\"line\">hash_method crc32; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p>其中,hash_method为使用的hash算法,需要注意的是:此时,server语句中不能加weight等参数。<br>\n提示:url_hash用途cache服务业务,memcached,squid,varnish。特点:每个rs都是不同的。</p>\n<p>参数说明:<br>\nserver address parameters<br>\nserver:关键字,必选。<br>\naddress:主机名、域名、ip或unix socket,也可以指定端口号,必选。<br>\nparameters:可选参数,可选参数如下:<br>\n1.down:表示当前server已停用<br>\n2.backup:表示当前server是备用服务器,只有其它非backup后端服务器都挂掉了或者很忙才会分配到请求。<br>\n3.weight:表示当前server负载权重,权重越大被请求几率越大。默认是1.<br>\n4.max_fails和fail_timeout一般会关联使用,如果某台server在fail_timeout时间内出现了max_fails次连接失败,那么Nginx会认为其已经挂掉了,从而在fail_timeout时间内不再去请求它,fail_timeout默认是10s,max_fails默认是1,即默认情况是只要发生错误就认为服务器挂掉了,如果将max_fails设置为0,则表示取消这项检查。</p>\n<figure class=\"highlight php\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">upstream backend &#123; </span><br><span class=\"line\">server backend1.example.com weight=<span class=\"number\">5</span>; </span><br><span class=\"line\">server <span class=\"number\">127.0</span><span class=\"number\">.0</span><span class=\"number\">.1</span>:<span class=\"number\">8080</span> max_fails=<span class=\"number\">3</span> fail_timeout=<span class=\"number\">30</span>s; </span><br><span class=\"line\">server unix:/tmp/backend3; </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[],"Tag":[]}}